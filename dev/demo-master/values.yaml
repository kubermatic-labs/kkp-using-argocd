# Copyright 2020 The Kubermatic Kubernetes Platform contributors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

nginx:
  controller:
    config:
      # FIXME: Not to be used in production environment. Using this only because we have staging cert for now.
      hsts: false

# Dex Is the OpenID Provider for Kubermatic.
dex:
  ingress:
    # configure your base domain, under which the Kubermatic dashboard shall be available
    host: argodemo.lab.kubermatic.io

  clients:
  # The "kubermatic" client is used for logging into the Kubermatic dashboard. It always
  # needs to be configured.
  - id: kubermatic
    name: Kubermatic
    # Generate a secure secret key
    # Those can be generated on the shell using:
    # cat /dev/urandom | tr -dc A-Za-z0-9 | head -c32
    secret: VNfJgZlth5fJ3BpSd5QSKGwBdKeFAkGk
    RedirectURIs:
    # ensure the URLs below use the dex.ingress.host configured above
    - https://argodemo.lab.kubermatic.io
    - https://argodemo.lab.kubermatic.io/projects

    # The "kubermaticIssuer" client is used for providing OIDC access to User Clusters.
    # This configuration is optional, used if the "enableOIDCKubeconfig: true" option is used in KubermaticSetting.
    # More about this configuration at https://docs.kubermatic.com/kubermatic/master/tutorials-howtos/oidc-provider-configuration/share-clusters-via-delegated-oidc-authentication/
  - id: kubermaticIssuer
    name: Kubermatic OIDC Issuer
    # Generate a secure secret key
    # Those can be generated on the shell using:
    # cat /dev/urandom | tr -dc A-Za-z0-9 | head -c32
    secret: IcT66lr0DT1BGD8zGXICL2azgnZ57VTd
    RedirectURIs:
      # ensure the URLs below use the dex.ingress.host configured above
      - https://argodemo.lab.kubermatic.io/api/v1/kubeconfig
      - https://argodemo.lab.kubermatic.io/api/v2/kubeconfig/secret
      - https://argodemo.lab.kubermatic.io/api/v2/dashboard/login

  - id: alertmanager
    name: AlertManager
    secret: 31XJHoWbktTYBbCIHchCeAaJtepPPS1W
    RedirectURIs:
    - https://alertmanager.argodemo.lab.kubermatic.io/oauth/callback
  - id: grafana
    name: Grafana
    secret: noBMZ3jhWbKlep2Op9jDfDWg1DMgydCX
    RedirectURIs:
    - https://grafana.argodemo.lab.kubermatic.io/oauth/callback
  - id: prometheus
    name: Prometheus
    secret: UXsiBXUnkpm8Xg1jQu1OYTBpfuazMC7X
    RedirectURIs:
    - https://prometheus.argodemo.lab.kubermatic.io/oauth/callback
  # India seed
  - id: alertmanager_india
    name: AlertManager for India seed cluster
    secret: Xi1k5yHpMqDrfzFDnYx7X81fcWbeAhcr
    RedirectURIs:
    - https://alertmanager.india.argodemo.lab.kubermatic.io/oauth/callback
  - id: grafana_india
    name: Grafana for India seed cluster
    secret: hdNKLfJ02K5bxT1DpWxR4o1iGBg4eqqt
    RedirectURIs:
    - https://grafana.india.argodemo.lab.kubermatic.io/oauth/callback
  - id: prometheus_india
    name: Prometheus for India seed cluster
    secret: SRqPgRKVLg3hd8srpdhqJUYwIL1BcS58
    RedirectURIs:
    - https://prometheus.india.argodemo.lab.kubermatic.io/oauth/callback
  # user-mla - self
  - id: grafana_user_self
    name: Grafana for Self User clusters
    secret: xK7EjZM2gmp3DRrl0APlMkNDcS1hEf7m
    RedirectURIs:
    - https://grafana-user.self.seed.argodemo.lab.kubermatic.io/oauth/callback
  - id: alertmanager_user_self
    name: AlertManager for Self User clusters
    secret: LBZSAXMklV6Z1OWqHF2Fphgale1zY4TP
    RedirectURIs:
    - https://alertmanager-user.self.seed.argodemo.lab.kubermatic.io/oauth/callback

  # user-mla - india - FIXME:

  # Depending on your chosen login method, you need to configure either an OAuth provider like
  # Google or GitHub, or configure a set of static passwords. Check the `charts/oauth/values.yaml`
  # for an overview over all available connectors.

  # For testing purposes, we configure a single static user/password combination.
  staticPasswords:
  - email: vijay@kubermatic.com
    # bcrypt hash of the string "password", can be created using recent versions of htpasswd:
    # `htpasswd -bnBC 10 "" PASSWORD_HERE | tr -d ':\n' | sed 's/$2y/$2a/'`
    # password: vj
    hash: "$2b$10$bdy3m5CmqsDFy8iBPvJSGe4p5I.L3UuMpmCnEZ3WjhiXRaz8VWNSi"

    # these are used within Kubermatic to identify the user
    username: admin
    userID: 08a8684b-db88-4b73-90a9-3cd1661f5466
  - email: yash@kubermatic.com
    # bcrypt hash of the string "password", can be created using recent versions of htpasswd:
    # `htpasswd -bnBC 10 "" PASSWORD_HERE | tr -d ':\n' | sed 's/$2y/$2a/'`
    # password: vj
    hash: "$2b$10$bdy3m5CmqsDFy8iBPvJSGe4p5I.L3UuMpmCnEZ3WjhiXRaz8VWNSi"


  # the cert-manager Issuer (or ClusterIssuer) responsible for managing the certificates
  # If you want to deploy your own certificate without relying on cert-manager
  # uncomment the next line and remove subsequent certIssuer configuration.
  # certIssuer: null
  certIssuer:
    # For generating a certificate signed by a trusted root authority replace
    # with "letsencrypt-prod".
    name: letsencrypt-prod
    kind: ClusterIssuer

telemetry:
  # uuid is the unique identifier of the client where the agent is running.
  # This field is required and will print an error message when that entry is missing.
  # You can generate uuid using command uuidgen on your linux machine
  uuid: cd190cf9-c3c7-4e22-9483-45fc994f55d7

promtail:
  podLabels:
    env: dev
loki:
  persistence:
    size: '10Gi'

iap:
  oidc_issuer_url: https://argodemo.lab.kubermatic.io/dex
  # FIXME: Need to change in production environment to use production letsencrypt.
  customProviderCA:
      secretName: letsencrypt-staging-ca-cert
      secretKey: ca.crt
  deployments:
    alertmanager:
      name: alertmanager
      client_id: alertmanager
      client_secret: 31XJHoWbktTYBbCIHchCeAaJtepPPS1W
      encryption_key: UADeR15wrVNEfqkhT8kIARNOA4Iy10un
      config: ## see https://github.com/oauth2-proxy/oauth2-proxy/blob/master/docs/configuration/configuration.md
        scope: "groups openid email"
        #allowed_groups: Kubermatic_Managed_Service_Team
        email_domains:
          - '*'
        ## do not route health endpoint through the proxy
        skip_auth_regex:
          - '/-/healthy'
      upstream_service: alertmanager.monitoring.svc.cluster.local
      upstream_port: 9093
      ingress:
        host: "alertmanager.argodemo.lab.kubermatic.io"
    grafana:
      name: grafana
      client_id: grafana
      client_secret: noBMZ3jhWbKlep2Op9jDfDWg1DMgydCX
      encryption_key: 48wG5FXnPFrfMbWgFRrZ70LqlYHn3vu0
      config: ## see https://github.com/oauth2-proxy/oauth2-proxy/blob/master/docs/configuration/configuration.md
        scope: "groups openid email"
        #allowed_groups: Kubermatic_Managed_Service_Team
        email_domains:
          - '*'
        ## do not route health endpoint through the proxy
        skip_auth_regex:
          - '/api/health'
        ## auto-register users based on their email address
        ## Grafana is configured to look for the X-Forwarded-Email header
        pass_user_headers: true
      # enable-authorization-header: false
      upstream_service: grafana.monitoring.svc.cluster.local
      upstream_port: 3000
      ingress:
        host: "grafana.argodemo.lab.kubermatic.io"
    prometheus:
      name: prometheus
      client_id: prometheus
      client_secret: UXsiBXUnkpm8Xg1jQu1OYTBpfuazMC7X
      encryption_key: 7jvKLRPcdnyAGadt9oKYvixpP3JhhrG2
      config: ## see https://github.com/oauth2-proxy/oauth2-proxy/blob/master/docs/configuration/configuration.md
        scope: "groups openid email"
        #allowed_groups: Kubermatic_Managed_Service_Team
        email_domains:
          - '*'
        ## do not route health endpoint through the proxy
        skip_auth_regex:
          - '/-/healthy'
      upstream_service: prometheus.monitoring.svc.cluster.local
      upstream_port: 9090
      ingress:
        host: "prometheus.argodemo.lab.kubermatic.io"
        annotations:
          ingress.kubernetes.io/upstream-hash-by: "ip_hash" ## needed for prometheus federations
    alertmanager1:
      name: alertmanager1
      client_id: alertmanager1
      client_secret: 31XJHoWbktTYBbCIHchCeAaJtepPPS1W
      encryption_key: UADeR15wrVNEfqkhT8kIARNOA4Iy10un
      config: ## see https://github.com/oauth2-proxy/oauth2-proxy/blob/master/docs/configuration/configuration.md
        scope: "groups openid email"
        #allowed_groups: Kubermatic_Managed_Service_Team
        email_domains:
          - '*'
        ## do not route health endpoint through the proxy
        skip_auth_regex:
          - '/-/healthy'
      upstream_service: kube-prometheus-stack-alertmanager.monitoring1.svc.cluster.local
      upstream_port: 9093
      ingress:
        host: "alertmanager1.argodemo.lab.kubermatic.io"

alertmanager:
  storageSize: 4Gi

minio:
  credentials:
    accessKey: '9XLR0TfxQYVnyIAYamS6dcWOKpbgjYOi' # 32 byte long
    secretKey: 'nkW9P6vG2bWfVcXG2BYhdcvlZSEWsYYDtPKKrbkxctgGjdId369u9OxOnoLMJNNW' # 64 byte long